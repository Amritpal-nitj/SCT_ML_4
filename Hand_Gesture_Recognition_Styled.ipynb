{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37723df",
   "metadata": {},
   "source": [
    "# ü§ñ Hand Gesture Recognition using CNN & OpenCV\n",
    "\n",
    "Welcome to this project where we build a **real-time hand gesture recognition system** using **Convolutional Neural Networks (CNN)** and **OpenCV**. This notebook walks you through the complete ML pipeline: from loading gesture images, training a deep learning model, to predicting gestures using webcam input.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Problem Statement\n",
    "\n",
    "The goal is to classify different hand gestures (like ‚úåÔ∏è, üëä, üëç) captured from a webcam or image dataset into predefined categories using machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Tech Stack\n",
    "\n",
    "- üêç Python 3\n",
    "- üì¶ TensorFlow/Keras\n",
    "- üì∑ OpenCV\n",
    "- üìä Matplotlib\n",
    "- üîé Scikit-learn\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356102a",
   "metadata": {},
   "source": [
    "## üìÅ Dataset Preparation\n",
    "\n",
    "Make sure your dataset is structured like this:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ 0/   # fist\n",
    "‚îú‚îÄ‚îÄ 1/   # palm\n",
    "‚îú‚îÄ‚îÄ 2/   # peace\n",
    "‚îú‚îÄ‚îÄ 3/   # okay\n",
    "‚îú‚îÄ‚îÄ 4/   # thumbs up\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train = datagen.flow_from_directory(\n",
    "    'dataset',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val = datagen.flow_from_directory(\n",
    "    'dataset',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996df14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(train.class_indices.keys())\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    img, label = train.next()\n",
    "    ax[i].imshow(img[0])\n",
    "    ax[i].set_title(f\"Label: {np.argmax(label[0])}\")\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29055103",
   "metadata": {},
   "source": [
    "## üß† Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58331d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(train.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8bb87",
   "metadata": {},
   "source": [
    "## üöÄ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527286fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, validation_data=val, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab260c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d0807",
   "metadata": {},
   "source": [
    "## üìä Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.reset()\n",
    "pred = model.predict(val)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = val.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gesture_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e3721",
   "metadata": {},
   "source": [
    "## üñêÔ∏è Real-Time Prediction with Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5defe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('gesture_model.h5')\n",
    "labels = list(train.class_indices.keys())\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    roi = frame[100:400, 100:400]\n",
    "    img = cv2.resize(roi, (64, 64)) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    pred = model.predict(img)\n",
    "    gesture = labels[np.argmax(pred)]\n",
    "\n",
    "    cv2.putText(frame, f'Gesture: {gesture}', (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.rectangle(frame, (100,100), (400,400), (255,0,0), 2)\n",
    "    cv2.imshow(\"Webcam Gesture Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e7e53",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "We successfully trained a CNN model to recognize hand gestures with high accuracy. This model can now be used in real-time applications like gesture-controlled interfaces or robotics.\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Next Steps\n",
    "\n",
    "- Add more gestures\n",
    "- Improve model accuracy with more data or transfer learning\n",
    "- Deploy as a web app using TensorFlow.js\n",
    "\n",
    "---\n",
    "\n",
   
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
